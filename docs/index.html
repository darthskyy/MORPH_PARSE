<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MorphParse: Deep Learning for Morphological Parsing</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="icon" href="files/uctlogo.png" type="image/x-icon">
</head>
<body>

<header>
    <div class="uct-logo">
        <img src="files/uctlogo.png" alt="University of Cape Town logo" class="uct-logo">
    </div>
    <nav>
        <div id="site-title">
            <strong>MorphParse</strong>
            <span id="site-subtitle">Deep Learning for Morphological Parsing</span>
        </div>
        <ul>
            <li><a href="#abstract">Abstract</a></li>
            <li><a href="#background">Background</a></li>
            <li><a href="#from-scratch">Models Trained From Scratch</a></li>
            <li><a href="#plms">Pre-trained Language Models</a></li>
            <li><a href="#results">Results</a></li>
        </ul>
    </nav>
</header>

<div id="main-wrap">
    <main>
        <section id="abstract">
            <h1>Abstract</h1>
            <p>
                <dfn>Morphemes</dfn> are the smallest units of meaning in a language. They play an important role in creating
                meaning and grammatical syntax. This is especially true in agglutinative languages, such as the Nguni languages,
                which construct words by concatenating many morphemes.Many Natural Language Processing (NLP) tasks, such as
                machine translation, can be improved by incorporating morphological information. However, methods to extract
                this information for the Nguni languages still need to be refined.

            <p>
                This paper evaluates the use of neural
                    methods in morphological parsing, or the labelling of morphemes with their corresponding grammatical role.
                We compare two main approaches:
                <ul>
                    <li><a href="#from-scratch">Training neural models from scratch</a>, and</li>
                    <li><a href="#plms">Fine-tuning pre-trained language models.</a></li>
                </ul>

            <p>We <a href="#results">compared the performance</a> of these models with
                each-other as well as with traditional methods of solving the task, such as Finite-State Transducer (FST) models.

            <p>
                We found that models trained from scratch outperformed both fine-tuned pre-trained language models and the
                traditional FST model. Models using morpheme-level embeddings and sentence-level context tended to perform the
                best.
        </section>

        <section id="background">
            <h1>Background</h1>
            <p>
                Project description
            </p>
        </section>

        <section id="from-scratch">
            <h1>Models Trained From Scratch</h1>
            <p class="author">Author: Cael Marquad</p>
            <p>Details about the exploration.</p>
            <div class="exploration-content">
                <div class="pdf-item">
                    <h3>Research Paper</h3>
                    <embed class="pdf-embed" src="files/MRQCAE001_MorphParse_report.pdf" type="application/pdf">
                </div>
                <div class="pdf-item">
                    <h3>Literature Review</h3>
                    <embed class="pdf-embed" src="files/MRQCAE001_MorphParse_literature_review.pdf" type="application/pdf">
                </div>
            </div>
        </section>

        <section id="plms">
            <h1>Pre-trained Language Models</h1>
            <p class="author">Author: Simbarashe Mawere</p>
            <p>Details about the exploration.</p>
            <div class="exploration-content">
                <div class="pdf-item">
                    <h3>Research Paper</h3>
                    <embed class="pdf-embed" src="files/MWRSIM003_MorphParse_Final_Report_site_version.pdf" type="application/pdf">
                </div>
                <div class="pdf-item">
                    <h3>Literature Review</h3>
                    <embed class="pdf-embed" src="path_to_your_literature_review2.pdf" type="application/pdf">
                </div>
            </div>
        </section>

        <section id="results">
            <h1>Results</h1>
            <p>Results of the exploration. Lorem ipsum dolor sit amet consectetur adipisicing elit. Porro impedit vitae minima quisquam animi magnam, cumque non sed reprehenderit, similique ullam necessitatibus laboriosam ea fuga, aliquam magni sint perferendis placeat quod modi expedita voluptates molestiae rem explicabo. Est voluptatibus dicta tenetur quis facere rem perspiciatis voluptatem officiis, exercitationem vitae autem! Earum, temporibus cupiditate iusto expedita consequuntur nesciunt perferendis, corporis pariatur maxime, voluptatum facere! Eaque officia, aspernatur totam quasi molestiae suscipit sint natus accusamus esse similique alias explicabo deleniti blanditiis? Dolorem iure in illo, animi repellat nisi nobis veniam neque omnis. Sunt dolorem reiciendis ab vitae! Inventore laborum iste veritatis consequatur.</p>


            <!-- Gold Data -->
            <h3>Results on Expert Annotated Canonical Segmentation</h3>
            <table id="gold-table">
                <thead>
                    <tr>
                        <th>Model</th>
                        <th colspan="2">isiNdebele</th>
                        <th colspan="2">siSwati</th>
                        <th colspan="2">isiXhosa</th>
                        <th colspan="2">isiZulu</th>
                    </tr>
                    <tr class="score-heading">
                        <th></th>
                        <th>Micro F1</th>
                        <th>Macro F1</th>
                        <th>Micro F1</th>
                        <th>Macro F1</th>
                        <th>Micro F1</th>
                        <th>Macro F1</th>
                        <th>Micro F1</th>
                        <th>Macro F1</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <th colspan="9">Baselines</th>
                    </tr>
                    <tr>
                        <td>ZulMorph</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>0.6471</td><td>0.3378</td>
                    </tr>
                    <tr>
                        <th colspan="9">Models Trained from Scratch</th>
                    </tr>
                    <tr>
                        <td>Bi-LSTM, morpheme</td><td>0.9222</td><td>0.6950</td><td>0.9160</td><td>0.6761</td><td>0.9529</td><td>0.7359</td><td>0.9264</td><td class="best"><u>0.6860</u></td>
                    </tr>
                    <tr>
                        <td>Bi-LSTM, char-sum</td><td class="best"><u>0.9226</u></td><td>0.6907</td><td>0.9177</td><td>0.6835</td><td>0.9553</td><td>0.7418</td><td>0.9271</td><td>0.6817</td>
                    </tr>
                    <tr>
                        <td>Bi-LSTM, morpheme</td><td>0.9188</td><td>0.7009</td><td>0.9190</td><td>0.6872</td><td>0.9609</td><td>0.7694</td><td>0.9263</td><td>0.6812</td>
                    </tr>
                    <tr>
                        <td>Bi-LSTM, char-sum</td><td>0.9142</td><td>0.6901</td><td>0.9132</td><td>0.6748</td><td>0.9585</td><td>0.7604</td><td>0.9210</td><td>0.6661</td>
                    </tr>
                    <tr>
                        <td>CRF, morpheme</td><td>0.9189</td><td class="best"><u>0.7047</u></td><td class="best"><u>0.9196</u></td><td class="best"><u>0.6945</u></td><td>0.9619</td><td class="best"><u>0.7777</u></td><td class="best"><strong>0.9272</strong></td><td>0.6825</td>
                    </tr>
                    <tr>
                        <td>CRF, char-sum</td><td>0.9167</td><td>0.7007</td><td>0.9179</td><td>0.6855</td><td class="best"><u>0.9623</u></td><td>0.7633</td><td>0.9255</td><td>0.6730</td>
                    </tr>
                    <tr>
                        <th colspan="9">Pre-trained Language Models</th>
                    </tr>
                    <tr>
                        <td>XLM-RoBERTa</td><td class="best"><strong>0.9152</strong></td><td class="best"><strong>0.6425</strong></td><td>0.9095</td><td>0.6420</td><td>0.9467</td><td>0.6773</td><td>0.9132</td><td>0.6157</td>
                    </tr>
                    <tr>
                        <td>Afro-XLMR</td><td>0.9133</td><td>0.6273</td><td class="best"><strong>0.9100</strong></td><td class="best"><strong>0.6460</strong></td><td class="best"><strong>0.9583</strong></td><td class="best"><strong>0.7363</strong></td><td class="best"><u>0.9282</u></td><td class="best"><strong>0.6610</strong></td>
                    </tr>
                    <tr>
                        <td>Nguni-XLMR</td><td>0.9104</td><td>0.6190</td><td>0.9042</td><td>0.6176</td><td>0.9488</td><td>0.6738</td><td>0.9187</td><td>0.6302</td>
                    </tr>
                </tbody>
            </table>            
            
            <!-- Canonical Segmentations -->
            <h3>End-to-End Results on Predicted Canonical Segmentations</h3>

            <table id="canonical-table">
                <thead>
                    <tr>
                        <th>Model</th>
                        <th colspan="2">isiNdebele</th>
                        <th colspan="2">siSwati</th>
                        <th colspan="2">isiXhosa</th>
                        <th colspan="2">isiZulu</th>
                    </tr>
                    <tr class="score-heading">
                        <th></th>
                        <th>Micro F<sub>1</sub></th>
                        <th>Macro F<sub>1</sub></th>
                        <th>Micro F<sub>1</sub></th>
                        <th>Macro F<sub>1</sub></th>
                        <th>Micro F<sub>1</sub></th>
                        <th>Macro F<sub>1</sub></th>
                        <th>Micro F<sub>1</sub></th>
                        <th>Macro F<sub>1</sub></th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <th colspan="9">Baselines</th>
                    </tr>
                    <tr>
                        <td>ZulMorph</td>
                        <td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>0.6471</td><td>0.3378</td>
                    </tr>
        
                    <!-- <tr><td colspan="9"><hr></td></tr> -->
        
                    <tr>
                        <th colspan="9">Models Trained from Scratch</th>
                    </tr>
                    <tr>
                        <td>Bi-LSTM, morpheme</td>
                        <td>0.8084</td><td>0.5769</td><td>0.8230</td><td>0.5717</td><td>0.9110</td><td>0.6807</td><td>0.8250</td><td>0.5936</td>
                    </tr>
                    <tr>
                        <td>Bi-LSTM, char-sum</td>
                        <td class="best"><strong>0.8094</strong></td><td class="best"><u>0.6816</u></td><td>0.8289</td><td>0.5760</td><td>0.9107</td><td>0.6816</td><td>0.8248</td><td class="best"><u>0.6033</u></td>
                    </tr>
                    
                    <tr>
                        <td>Bi-LSTM, morpheme<br>(Sentence-level)</td>
                        <td>0.8059</td><td>0.5834</td><td>0.8274</td><td>0.5792</td><td>0.9172</td><td>0.7171</td><td>0.8265</td><td>0.5989</td>
                    </tr>
                    <tr>
                        <td>Bi-LSTM, char-sum<br>(Sentence-level)</td>
                        <td>0.8010</td><td>0.5814</td><td>0.8238</td><td>0.5749</td><td>0.9135</td><td>0.7020</td><td>0.8184</td><td>0.5903</td>
                    </tr>
                    <tr>
                        <td>CRF, morpheme<br>(Sentence-level)</td>
                        <td>0.8049</td><td>0.5961</td><td class="best"><u>0.8301</u></td><td class="best"><u>0.5860</u></td><td class="best"><u>0.9190</u></td><td class="best"><u>0.7224</u></td><td class="best"><u>0.8280</u></td><td>0.5991</td>
                    </tr>
                    <tr>
                        <td>CRF, char-sum<br>(Sentence-level)</td>
                        <td>0.8081</td><td>0.5893</td><td>0.8271</td><td>0.5782</td><td>0.9181</td><td>0.7084</td><td>0.8246</td><td>0.5973</td>
                    </tr>
        
                    <tr>
                        <th colspan="9">Pre-trained Language Models</th>
                    </tr>
                    <tr>
                        <td>XLM-RoBERTa</td>
                        <td class="best"><u>0.8151</u></td><td class="best"><strong>0.5509</strong></td><td class="best"><strong>0.8280</strong></td><td>0.5278</td><td>0.9137</td><td>0.6346</td><td>0.8251</td><td>0.5438</td>
                    </tr>
                    <tr>
                        <td>Afro-XLMR</td>
                        <td>0.8137</td><td>0.5413</td><td>0.8273</td><td class="best"><strong>0.5296</strong></td><td class="best"><strong>0.9140</strong></td><td class="best"><strong>0.6423</strong></td><td>0.8269</td><td>0.5469</td>
                    </tr>
                    <tr>
                        <td>Nguni-XLMR</td>
                        <td>0.8144</td><td>0.5468</td><td>0.8264</td><td>0.5285</td><td>0.9155</td><td>0.6390</td><td class="best"><strong>0.8272</strong></td><td class="best"><strong>0.5495</strong></td>
                    </tr>
                </tbody>
            </table>

            <!-- Surface Segmentations -->
            <h3>End-to-End Results on Predicted Surface Segmentations</h3>
            <table>
                <thead>
                    <tr>
                        <th>Model</th>
                        <th colspan="2">isiNdebele</th>
                        <th colspan="2">siSwati</th>
                        <th colspan="2">isiXhosa</th>
                        <th colspan="2">isiZulu</th>
                    </tr>
                    <tr class="score-heading">
                        <th></th>
                        <th>Micro F<sub>1</sub></th>
                        <th>Macro F<sub>1</sub></th>
                        <th>Micro F<sub>1</sub></th>
                        <th>Macro F<sub>1</sub></th>
                        <th>Micro F<sub>1</sub></th>
                        <th>Macro F<sub>1</sub></th>
                        <th>Micro F<sub>1</sub></th>
                        <th>Macro F<sub>1</sub></th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <th colspan="9">Models Trained from Scratch</th>
                    </tr>
                    <tr>
                        <td>Bi-LSTM, morpheme</td><td class="best"><strong><u>0.7830</u></strong></td><td class="best"><strong><u>0.5409</u></strong></td><td class="best"><strong><u>0.8129</u></strong></td><td class="best"><strong><u>0.5274</u></strong></td><td class="best"><strong><u>0.8661</u></strong></td><td class="best"><strong><u>0.6724</u></strong></td><td class="best"><strong><u>0.8023</u></strong></td><td class="best"><strong><u>0.5529</u></strong></td>
                    </tr>
                    <tr>
                        <td>Bi-LSTM, char-sum</td><td>0.7742</td><td>0.5238</td><td>0.8053</td><td>0.5212</td><td>0.7994</td><td>0.6054</td><td>0.7976</td><td>0.5511</td>
                    </tr>
                    <tr>
                        <th colspan="9">Pre-trained Language Models</th>
                    </tr>
                    <tr>
                        <td>XLM-RoBERTa</td><td class="best"><strong>0.7282</strong></td><td>0.4868</td><td>0.5107</td><td>0.2231</td><td>0.7244</td><td>0.5208</td><td>0.6759</td><td>0.4349</td>
                    </tr>
                    <tr>
                        <td>Afro-XLMR</td><td>0.7275</td><td>0.4832</td><td>0.5216</td><td>0.2412</td><td>0.7273</td><td class="best"><strong>0.5300</strong></td><td>0.6794</td><td>0.4495</td>
                    </tr>
                    <tr>
                        <td>Nguni-XLMR</td><td>0.7258</td><td>0.4746</td><td class="best"><strong>0.5328</strong></td><td class="best"><strong>0.2505</strong></td><td class="best"><strong>0.7309</strong></td><td>0.5270</td><td class="best"><strong>0.6818</strong></td><td class="best"><strong>0.4512</strong></td>
                    </tr>
                </tbody>
            </table>
        </section>
    </main>
</div>

<footer>
    <p>&copy; 2024 MorphParse | By Simbarashe Mawere and Cael Marquard</p>
</footer>

<script src="script.js"></script>
</body>
</html>
